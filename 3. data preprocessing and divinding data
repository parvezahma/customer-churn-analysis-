#
le = LabelEncoder()

for col in categorical_features:
    df[col] = le.fit_transform(df[col])


# feature scaling
X = df.drop("churn", axis=1)
y = df["churn"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Handle missing values before train-test split and scaling
# Using SimpleImputer to fill missing values with the median for numerical columns.
from sklearn.impute import SimpleImputer

# Identify columns with missing values (from GWv_isyMhVuN)
missing_cols = ['reamining_contract', 'download_avg', 'upload_avg']

# Create a copy to avoid modifying the original df directly in place if it's a view
df_processed = df.copy()

imputer = SimpleImputer(strategy='median')

for col in missing_cols:
    if col in df_processed.columns:
        df_processed[col] = imputer.fit_transform(df_processed[[col]])

print("Missing values after imputation:")
print(df_processed[missing_cols].isnull().sum())

# Now, proceed with feature scaling and train-test split using df_processed

X = df_processed.drop("churn", axis=1)
y = df_processed["churn"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# lets use the train test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)




Missing values after imputation:
reamining_contract    0
download_avg          0
upload_avg            0




